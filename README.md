<p align="center">
  <img src="MemoTime_logo.png" alt="MemoTime_logo" width="180"/>
</p>



# MemoTime: Memory-Augmented Temporal Knowledge Graph Enhanced Large Language Model Reasoning [WWW 2026]

---

## News!
Our paper has been accepted for publication at WWW 2026! 

## How to cite
If you are interested or inspired by this work, you can cite us by:
```sh
@article{tan2025memotime,
  title={Memotime: Memory-augmented temporal knowledge graph enhanced large language model reasoning},
  author={Tan, Xingyu and Wang, Xiaoyang and Liu, Qing and Xu, Xiwei and Yuan, Xin and Zhu, Liming and Zhang, Wenjie},
  journal={arXiv preprint arXiv:2510.13614},
  year={2025}
}
```

---

## ðŸ“„ Abstract

Large Language Models exhibit strong reasoning abilities but often fail to maintain **temporal consistency** when questions involve multiple entities, compound operators, and evolving event sequences.

<p align="center">
  <img src="MemoTime.jpg" alt="MemoTime"/>
</p>


**MemoTime** addresses four key challenges:
(1) maintaining temporal faithfulness in multi-hop reasoning,
(2) synchronizing multiple entities along shared timelines,
(3) adapting retrieval to diverse temporal operators, and
(4) reusing prior reasoning experience for efficiency and stability.
MemoTime decomposes complex temporal questions into a hierarchical **Tree of Time**, enabling operator-aware reasoning with dynamic evidence retrieval and a self-evolving experience memory for continual improvement.


---

## ðŸ“¦ Project Structure

```
MemoTime/
â”œâ”€â”€ memotime/                       # Main source code
â”‚   â”œâ”€â”€ run.py                      # CLI interface
â”‚   â”œâ”€â”€ main.py                     # Experiment runner
â”‚   â”œâ”€â”€ config.py                   # Configuration management
â”‚   â”œâ”€â”€ data_process.py             # Dataset handling
â”‚   â”œâ”€â”€ experiment_database.py      # Experiment tracking
â”‚   â””â”€â”€ kg_agent/                   # Core reasoning engine
â”‚       â”œâ”€â”€ agent.py                # Main reasoning agent
â”‚       â”œâ”€â”€ stepwise.py             # Recursive decomposition logic
â”‚       â”œâ”€â”€ decompose.py            # Question decomposition
â”‚       â”œâ”€â”€ hybrid_retrieval.py     # Hybrid retrieval strategies
â”‚       â”œâ”€â”€ unified_knowledge_store.py  # Experience memory
â”‚       â”œâ”€â”€ answer_verifier.py      # Answer verification
â”‚       â”œâ”€â”€ prompts.py              # General prompts
â”‚       â”œâ”€â”€ fixed_prompts.py        # Toolkit initialization prompts
â”‚       â”œâ”€â”€ llm.py                  # LLM interface
â”‚       â””â”€â”€ ...                     # Other components
â”œâ”€â”€ Data/                           # Dataset directory
â”‚   â”œâ”€â”€ prepare_datasets.py         # Dataset preparation script
â”‚   â”œâ”€â”€ TimeQuestions/              # TimeQuestions dataset
â”‚   â””â”€â”€ MultiTQ/                    # MultiTQ dataset

```

---

## ðŸš€ Quick Start

### 1. Installation

```bash
git clone <URL>
cd WWW-MemoTime-Submit

# install requirements
bash setup_dependencies.sh

# Install verification
python verify_installation.py

```

### 2. Configure API Keys

Edit the following lines in `memotime/kg_agent/llm.py`:

```python
DEFAULT_OPENAI_API_KEY = "your-openai-api-key"
```

### 3. Prepare Datasets
The process including whole graph constrcution, graph indexing, hybird indexing, and topic entity recognization. You can choose how many question you want for entity recognization by flag "-n".

```bash
cd Data
# Prepare for all datasets
python prepare_datasets.py --dataset all --build-hybrid --build-embeddings

# Prepare for MultiTQ
python prepare_datasets.py --dataset MultiTQ --build-hybrid --build-embeddings

# Process only 10 questions for MultiTQ
python prepare_datasets.py --dataset TimeQuestions -n 20

# If you already have DB and index, just generate candidates for 20 questions
python prepare_datasets.py --dataset TimeQuestions -n 20 --skip-db --skip-index

```

---

##  ðŸ’» Usage

### Basic Commands

```bash
cd ../memotime
# Run experiments
python run.py --questions 5 --dataset MultiTQ

# Run with detailed configuration
python run.py --retries 2 --depth 3 --hybrid --unified-knowledge --dataset MultiTQ --questions 50

# Run by question type
python run.py --dataset MultiTQ --type equal --questions 20
```

### View Help and Results

```bash
# Show all available options
python run.py --help
```

**Parameter categories:**

* **Experiment configuration:** `--dataset`, `--name`, `--desc`, `--tags`
* **Feature flags:** `--hybrid`, `--unified-knowledge`
* **Storage mode:** `--storage-mode`, `--enable-shared-fallback`, `--config-name`
* **Experiment range:** `--questions`, `--skip`, `--type`, `--entities`
* **LLM configuration:** `--model`
* **Miscellaneous:** `--result`, `--no-save`, `--verbose`

```bash
# View experiment results
python run.py --result --name my_experiment
python run.py --result --preset accuracy_mode
```

**Result view includes:**

* Configuration summary and run history
* Success rate by overall and question type
* Answer type and temporal granularity statistics

---

## ðŸ“„ License

Released under the **MIT License**. See [LICENSE](LICENSE) for details.

